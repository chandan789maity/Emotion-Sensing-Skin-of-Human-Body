{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868014f2-f83b-473c-8d9c-8d1bf1cc9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "merge_data = pd.read_csv(\"merge_data.csv\")\n",
    "\n",
    "# Convert Gender column: male to 1, female to 0\n",
    "merge_data['Gender'] = merge_data['Gender'].str.strip().str.lower().map({'male': 1, 'female': 0})\n",
    "\n",
    "# Convert Familiarity Score: previously watched to 1, otherwise to 0\n",
    "merge_data['Familiarity Score'] = merge_data['Familiarity Score'].str.strip().str.lower().map({'Never watched': 0, 'otherwise': 1})\n",
    "\n",
    "# Handle NaN values by filling them with a default value (e.g., 0)\n",
    "merge_data['Gender'] = merge_data['Gender'].fillna(0).astype(int)\n",
    "merge_data['Familiarity Score'] = merge_data['Familiarity Score'].fillna(0).astype(int)\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "merge_data.to_csv(\"merge_update.csv\", index=False)\n",
    "\n",
    "print(\"Data updated and saved to merge_update.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ed931-ddff-429b-ace3-441128b1109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "\n",
    "# Load the dataset\n",
    "gsr_summary = pd.read_csv(\"merge_update.csv\")\n",
    "\n",
    "# Define features and target variable\n",
    "X = gsr_summary.drop(columns=[\"Emotion\"])\n",
    "y = gsr_summary[\"Emotion\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=3),\n",
    "    'Random Forest': RandomForestClassifier(random_state=3),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=3),\n",
    "    'SVM': SVC(probability=True, random_state=3),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=3),\n",
    "    'MLP': MLPClassifier(max_iter=1000, random_state=3),\n",
    "    'Ridge Classifier': RidgeClassifier()\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "roc_aucs = {}\n",
    "fprs = {}\n",
    "tprs = {}\n",
    "\n",
    "# Binarize the output\n",
    "y_train_bin = label_binarize(y_train, classes=np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy_scores[clf_name] = accuracy_score(y_test, y_pred)\n",
    "    precision_scores[clf_name] = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    recall_scores[clf_name] = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    f1_scores[clf_name] = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_score = clf.predict_proba(X_test_scaled)\n",
    "    else:\n",
    "        y_score = clf.decision_function(X_test_scaled)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "    \n",
    "    # Interpolate to make the plot smooth\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    \n",
    "    roc_aucs[clf_name] = roc_auc_micro\n",
    "    fprs[clf_name] = all_fpr\n",
    "    tprs[clf_name] = mean_tpr\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy Scores:\")\n",
    "for clf_name, acc in accuracy_scores.items():\n",
    "    print(f\"{clf_name}: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision Scores:\")\n",
    "for clf_name, prec in precision_scores.items():\n",
    "    print(f\"{clf_name}: {prec:.4f}\")\n",
    "\n",
    "print(\"\\nRecall Scores:\")\n",
    "for clf_name, rec in recall_scores.items():\n",
    "    print(f\"{clf_name}: {rec:.4f}\")\n",
    "\n",
    "print(\"\\nF1 Scores:\")\n",
    "for clf_name, f1 in f1_scores.items():\n",
    "    print(f\"{clf_name}: {f1:.4f}\")\n",
    "\n",
    "# Plot AUC curve\n",
    "plt.figure(figsize=(12, 9))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'yellow', 'cyan', 'magenta'])\n",
    "\n",
    "for clf_name, color in zip(classifiers.keys(), colors):\n",
    "    plt.plot(fprs[clf_name], tprs[clf_name], color=color, lw=2,\n",
    "             label=f'{clf_name} (AUC = {roc_aucs[clf_name]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "# Save as PDF\n",
    "plt.savefig('roc_curve_plot_with_user_data.pdf', format='pdf')\n",
    "# Save as PNG\n",
    "plt.savefig('roc_curve_plot.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8370d97-3c9b-4c7c-8779-df1ec3c3dfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee0232-abc5-4011-93e4-03a315fb99d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

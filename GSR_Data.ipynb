{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cede5-97cb-4dc2-b6f5-76321cfaf4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import ast\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve,ConfusionMatrixDisplay,RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021cc4f1-ad4b-4951-b6a3-ae9cc1e14970",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus=pd.read_excel(\"Stimulus_Description.xlsx\")\n",
    "stimulus[\"Target Emotion\"]=stimulus[\"Target Emotion\"].str.title()\n",
    "stimulus.info()\n",
    "stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b0a2f-2e0b-4b26-8d8c-42452ee22667",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus=pd.read_excel(\"Self-annotation Multimodal_Use.xlsx\")\n",
    "stimulus.info()\n",
    "stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97802c1e-9c3f-47dc-8282-19b8a9a14912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first run only\n",
    "gsr_data=pd.read_excel(\"Self-annotation Multimodal_Use.xlsx\")\n",
    "gsr_data[\"filename\"]=\"GSRdata_s\"+gsr_data[\"Session ID\"].astype(str)+\"p\"+gsr_data[\"Participant Id\"].astype(str)+\"v\"+gsr_data[\"Video ID\"].astype(str)+\".dat\"\n",
    "PATH_2=\"GSR/\"\n",
    "gsr_data[\"filename\"]=gsr_data[\"filename\"].str.replace('GSRdata_s2p9v3.dat','GSRdata_S2p9v3.dat',regex=False)\n",
    "gsr_data[\"GSR_list\"]=gsr_data[\"filename\"].apply(lambda x: list(pd.read_table(PATH_2+x).iloc[:,0]))\n",
    "gsr_data=gsr_data.merge(stimulus.iloc[:,0:3],on=[\"Session ID\",\"Video ID\"])\n",
    "gsr_data.to_csv(\"gsr_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb470c5c-4334-4c60-8ca1-2b8b056c6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_data=pd.read_csv(\"gsr_data.csv\")\n",
    "gsr_data.info()\n",
    "gsr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361e175-07fe-48b9-bb94-f0cc10d18308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first run only\n",
    "gsr_summary=gsr_data[[\"Emotion\",\"GSR_list\"]].copy()\n",
    "gsr_summary[\"GSR_list\"]=gsr_summary[\"GSR_list\"].apply(lambda x: ast.literal_eval(x))\n",
    "gsr_summary[\"min\"]=gsr_summary[\"GSR_list\"].apply(lambda x: np.min(x))\n",
    "gsr_summary[\"max\"]=gsr_summary[\"GSR_list\"].apply(lambda x: np.max(x))\n",
    "gsr_summary[\"mean\"]=gsr_summary[\"GSR_list\"].apply(lambda x: np.mean(x))\n",
    "gsr_summary[\"variance\"]=gsr_summary[\"GSR_list\"].apply(lambda x: np.var(x))\n",
    "gsr_summary[\"kurtosis\"]=gsr_summary[\"GSR_list\"].apply(lambda x: stat.kurtosis(x))\n",
    "gsr_summary[\"skewness\"]=gsr_summary[\"GSR_list\"].apply(lambda x: stat.skew(x))\n",
    "gsr_summary[\"first_quartile\"] = gsr_summary[\"GSR_list\"].apply(lambda x: np.percentile(x, 25))\n",
    "gsr_summary[\"third_quartile\"] = gsr_summary[\"GSR_list\"].apply(lambda x: np.percentile(x, 75))\n",
    "gsr_summary[\"median\"] = gsr_summary[\"GSR_list\"].apply(lambda x: np.median(x))\n",
    "gsr_summary=gsr_summary.drop(columns=[\"GSR_list\"])\n",
    "gsr_summary.to_csv(\"gsr_summary.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f6350-6ee3-46f6-a6a9-4daede48239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_summary=pd.read_csv(\"gsr_summary.csv\")\n",
    "gsr_summary.info()\n",
    "gsr_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba426e9-ae83-4432-9318-3e41cf13e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first run only\n",
    "gsr_proc=gsr_data[[\"Emotion\",\"GSR_list\"]].copy()\n",
    "gsr_proc[\"GSR_list\"]=gsr_proc[\"GSR_list\"].apply(lambda x: ast.literal_eval(x))\n",
    "gsr_proc=pd.concat([gsr_proc,pd.DataFrame(gsr_proc['GSR_list'].tolist())],axis=1).drop(columns=[\"GSR_list\"])\n",
    "for i in range(gsr_proc.shape[1]-1):\n",
    "    gsr_proc[i]=pd.to_numeric(gsr_proc[i])\n",
    "gsr_proc.to_csv(\"gsr_proc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae8a55-d3f5-41fe-a572-16c6bd761068",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_proc=pd.read_csv(\"gsr_proc.csv\")\n",
    "gsr_proc.info()\n",
    "gsr_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df458283-e663-4664-8893-d4008d1fc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(data_arr, title = ''):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    for index, row in data_arr.iterrows():\n",
    "        y = row\n",
    "        plt.plot(y)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Skin conductivity\")\n",
    "    plt.xlabel(\"Record index\")\n",
    "    plt.show()\n",
    "\n",
    "for i in emos:\n",
    "    plot_signals(gsr_proc[gsr_proc[\"Emotion\"]==i].iloc[:,1:4998:400], \"GSR Signal - \"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5dba5-c979-4627-a751-a81594321181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'gsr_proc.csv'  # Replace with the path to your CSV file\n",
    "gsr_proc = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the first 'Happy' row\n",
    "happy_row = gsr_proc[gsr_proc[\"Emotion\"] == \"Happy\"].iloc[0]\n",
    "\n",
    "# Drop the 'Emotion' column\n",
    "happy_values = happy_row.drop(labels=\"Emotion\").values.astype(float)\n",
    "\n",
    "# Generate time stamps\n",
    "time_stamps = range(len(happy_values))\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time_stamps, happy_values, label='Happy')\n",
    "plt.xlabel('Time Stamp')\n",
    "plt.ylabel('GSR Value')\n",
    "plt.title('GSR Values for Happy Emotion Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec1868-130c-422c-85de-5060ab117cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'gsr_proc.csv'  # Replace with the path to your CSV file\n",
    "gsr_proc = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the first 'Happy' row\n",
    "happy_row = gsr_proc[gsr_proc[\"Emotion\"] == \"Sad\"].iloc[0]\n",
    "\n",
    "# Drop the 'Emotion' column\n",
    "happy_values = happy_row.drop(labels=\"Emotion\").values.astype(float)\n",
    "\n",
    "# Generate time stamps\n",
    "time_stamps = range(len(happy_values))\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time_stamps, happy_values, label='Sad')\n",
    "plt.xlabel('Time Stamp')\n",
    "plt.ylabel('GSR Value')\n",
    "plt.title('GSR Values for Happy Emotion Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46a8ed-14a3-4183-b14e-edea1a9705a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "# Load the dataset\n",
    "gsr_summary = pd.read_csv(\"gsr_summary.csv\")\n",
    "\n",
    "# Define features and target variable\n",
    "X = gsr_summary.drop(columns=[\"Emotion\"])\n",
    "y = gsr_summary[\"Emotion\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=3),\n",
    "    'Random Forest': RandomForestClassifier(random_state=3),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=3),\n",
    "    'SVM': SVC(probability=True, random_state=3),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=3),\n",
    "    'MLP': MLPClassifier(max_iter=1000, random_state=3),\n",
    "    'Ridge Classifier': RidgeClassifier()\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "roc_aucs = {}\n",
    "fprs = {}\n",
    "tprs = {}\n",
    "\n",
    "# Binarize the output\n",
    "y_train_bin = label_binarize(y_train, classes=np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy_scores[clf_name] = accuracy_score(y_test, y_pred)\n",
    "    precision_scores[clf_name] = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    recall_scores[clf_name] = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    f1_scores[clf_name] = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_score = clf.predict_proba(X_test_scaled)\n",
    "    else:\n",
    "        y_score = clf.decision_function(X_test_scaled)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "    \n",
    "    roc_aucs[clf_name] = roc_auc_micro\n",
    "    fprs[clf_name] = fpr_micro\n",
    "    tprs[clf_name] = tpr_micro\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy Scores:\")\n",
    "for clf_name, acc in accuracy_scores.items():\n",
    "    print(f\"{clf_name}: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision Scores:\")\n",
    "for clf_name, prec in precision_scores.items():\n",
    "    print(f\"{clf_name}: {prec:.4f}\")\n",
    "\n",
    "print(\"\\nRecall Scores:\")\n",
    "for clf_name, rec in recall_scores.items():\n",
    "    print(f\"{clf_name}: {rec:.4f}\")\n",
    "\n",
    "print(\"\\nF1 Scores:\")\n",
    "for clf_name, f1 in f1_scores.items():\n",
    "    print(f\"{clf_name}: {f1:.4f}\")\n",
    "\n",
    "# Plot AUC curve\n",
    "plt.figure(figsize=(14, 7))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'yellow', 'cyan', 'magenta'])\n",
    "\n",
    "for clf_name, color in zip(classifiers.keys(), colors):\n",
    "    plt.plot(fprs[clf_name], tprs[clf_name], color=color, lw=2,\n",
    "             label=f'{clf_name} (AUC = {roc_aucs[clf_name]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14832f4-4259-436d-ae34-99aecdca9e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
